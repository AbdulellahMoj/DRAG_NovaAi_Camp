{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ca9d12",
   "metadata": {},
   "source": [
    "![Header](../assets/Header_NovaAi_Camp2.0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7098bbc",
   "metadata": {},
   "source": [
    "# Day 1: Scikit-Learn Basics üöÄ\n",
    "\n",
    "## Welcome to Professional Machine Learning\n",
    "\n",
    "In the previous notebook, we built everything from scratch to understand the fundamentals. Now it's time to use the tools that data scientists use in the real world.\n",
    "\n",
    "**You learned:**\n",
    "- How to calculate slope and intercept manually\n",
    "- How to compute MAE, MSE, RMSE, R¬≤ from formulas\n",
    "- How to split data into training and test sets\n",
    "- Why evaluation metrics matter\n",
    "\n",
    "**Now we'll do the exact same things**, but using professional tools that make everything faster and easier.\n",
    "\n",
    "## What is Scikit-Learn (sklearn)?\n",
    "\n",
    "Scikit-learn is the most popular machine learning library in Python. It's used by companies worldwide for everything from fraud detection to recommendation systems.\n",
    "\n",
    "**Think of it like this:**\n",
    "- **From Scratch** = Learning how a car engine works (educational, teaches fundamentals)\n",
    "- **Scikit-Learn** = Driving the car (practical, gets you where you need to go)\n",
    "\n",
    "You did the first part - now you understand HOW it works. Now let's learn to USE it effectively.\n",
    "\n",
    "## Why Use Scikit-Learn?\n",
    "\n",
    "| Feature | Benefit |\n",
    "|---------|---------|\n",
    "| **Automatic Math** | Complex formulas handled internally |\n",
    "| **Speed** | Optimized C/C++ code under the hood |\n",
    "| **Consistent API** | Same pattern for all models |\n",
    "| **Scalability** | Works with 1 or 1,000 features |\n",
    "| **Production Ready** | Battle-tested by millions of users |\n",
    "| **Rich Library** | 100+ algorithms included |\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Linear Regression** - The sklearn way\n",
    "2. **Train-Test Split** - One line of code\n",
    "3. **Model Evaluation** - Built-in metrics\n",
    "4. **Multiple Features** - No matrix math needed\n",
    "5. **Making Predictions** - Clean and simple\n",
    "\n",
    "Let's dive in! üí°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1c2c5",
   "metadata": {},
   "source": [
    "## Import Libraries üì¶\n",
    "\n",
    "Before we start, let's import our tools:\n",
    "\n",
    "- **Pandas** - For working with data tables\n",
    "- **NumPy** - For numerical operations\n",
    "- **Matplotlib** - For visualizations\n",
    "- **Sklearn** - For machine learning\n",
    "\n",
    "**Key Sklearn Components:**\n",
    "- `LinearRegression` - The model we'll use\n",
    "- `train_test_split` - Splits data automatically\n",
    "- `mean_absolute_error`, `mean_squared_error`, `r2_score` - Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.linear_model import LinearRegression      # The model\n",
    "from sklearn.model_selection import train_test_split  # Train/test split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # Evaluation metrics\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")\n",
    "print(\"Ready to use scikit-learn! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3867050",
   "metadata": {},
   "source": [
    "# Part 1: Linear Regression with Scikit-Learn üéØ\n",
    "\n",
    "## The Sklearn Workflow - Universal Recipe\n",
    "\n",
    "Scikit-learn follows a **consistent pattern** for ALL models. This is one of its best features!\n",
    "\n",
    "### The 3-Step Recipe\n",
    "\n",
    "```\n",
    "Step 1: CREATE        ‚Üí  model = LinearRegression()\n",
    "                         (Get a blank model ready to learn)\n",
    "\n",
    "Step 2: FIT           ‚Üí  model.fit(X, y)\n",
    "                         (Train the model on your data)\n",
    "\n",
    "Step 3: PREDICT       ‚Üí  predictions = model.predict(X_new)\n",
    "                         (Use the trained model on new data)\n",
    "```\n",
    "\n",
    "**This SAME pattern works for:**\n",
    "- Linear Regression (what we're learning)\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Neural Networks\n",
    "- And 100+ other algorithms!\n",
    "\n",
    "**Learn it once, use it everywhere.** That's the power of good design! ‚ú®\n",
    "\n",
    "---\n",
    "\n",
    "## Create Sample Dataset\n",
    "\n",
    "Let's start with a simple example: predicting house prices from square footage.\n",
    "\n",
    "**Remember this from the previous notebook?** Same data, different tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple dataset\n",
    "data = {\n",
    "    'Square_Feet': [1000, 1500, 2000, 2500, 3000],\n",
    "    'Price': [250000, 350000, 450000, 550000, 650000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Our Dataset:\")\n",
    "print(\"=\"*50)\n",
    "print(df)\n",
    "print(\"\\nüìä Goal: Predict house price from square footage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad348e3",
   "metadata": {},
   "source": [
    "## Prepare Data for Sklearn\n",
    "\n",
    "**IMPORTANT:** Sklearn expects data in a specific format. This trips up many beginners!\n",
    "\n",
    "### The Rules:\n",
    "\n",
    "**X (Features) must be 2D:**\n",
    "```python\n",
    "X = df[['Square_Feet']]  # Double brackets [[ ]] ‚Üí Creates a 2D DataFrame\n",
    "# Shape: (5, 1) - 5 samples, 1 feature\n",
    "```\n",
    "\n",
    "**y (Target) can be 1D:**\n",
    "```python\n",
    "y = df['Price']  # Single brackets [ ] ‚Üí Creates a 1D Series\n",
    "# Shape: (5,) - 5 samples\n",
    "```\n",
    "\n",
    "### Why 2D for X?\n",
    "\n",
    "Sklearn needs to handle multiple features, so it always expects a table structure:\n",
    "\n",
    "**One feature (our current example):**\n",
    "```python\n",
    "X = [[1000],   # House 1: 1000 sq ft\n",
    "     [1500],   # House 2: 1500 sq ft\n",
    "     [2000]]   # House 3: 2000 sq ft\n",
    "# Shape: (3, 1) - 3 houses, 1 feature\n",
    "```\n",
    "\n",
    "**Multiple features (we'll see this later):**\n",
    "```python\n",
    "X = [[1000, 3, 2],  # House 1: [sqft, bedrooms, bathrooms]\n",
    "     [1500, 4, 2],  # House 2\n",
    "     [2000, 5, 3]]  # House 3\n",
    "# Shape: (3, 3) - 3 houses, 3 features\n",
    "```\n",
    "\n",
    "**Key Point:** Always use double brackets `[[]]` for features, even with just one feature.\n",
    "\n",
    "**Think of it as:** Sklearn wants a table (DataFrame), not a list (Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) - needs to be 2D\n",
    "X = df[['Square_Feet']]  # Double brackets [[]] make it 2D\n",
    "\n",
    "# Prepare target (y) - can be 1D\n",
    "y = df['Price']  # Single brackets [] make it 1D\n",
    "\n",
    "print(\"Feature Matrix (X):\")\n",
    "print(X)\n",
    "print(f\"Shape: {X.shape} - (5 samples, 1 feature)\\n\")\n",
    "\n",
    "print(\"Target Vector (y):\")\n",
    "print(y.values)\n",
    "print(f\"Shape: {y.shape} - (5 samples,)\")\n",
    "\n",
    "print(\"\\n‚úì Data ready for sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b9193",
   "metadata": {},
   "source": [
    "## Step 1: Create the Model\n",
    "\n",
    "Creating a model is like getting a blank notebook - ready to learn but currently empty.\n",
    "\n",
    "```python\n",
    "model = LinearRegression()\n",
    "```\n",
    "\n",
    "**What happens here:**\n",
    "- A blank LinearRegression model is created\n",
    "- It has NO knowledge yet\n",
    "- Parameters (slope, intercept) are uninitialized\n",
    "- It's ready to learn but hasn't seen any data\n",
    "\n",
    "Think of it as hiring a student on their first day - they have potential but haven't studied yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"‚úì Model created!\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(\"\\nThe model is ready to learn, but hasn't seen any data yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3381b",
   "metadata": {},
   "source": [
    "## Step 2: Train (Fit) the Model üèãÔ∏è\n",
    "\n",
    "Training teaches the model to recognize patterns in your data.\n",
    "\n",
    "```python\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "**All the math we did manually before?** Sklearn does it in milliseconds! ‚ö°\n",
    "\n",
    "**What happens during `.fit()`:**\n",
    "\n",
    "**BEFORE:**\n",
    "```python\n",
    "model.coef_      # Doesn't exist yet\n",
    "model.intercept_ # Doesn't exist yet\n",
    "```\n",
    "\n",
    "**DURING (sklearn automatically):**\n",
    "1. Analyzes the relationship between X and y\n",
    "2. Calculates optimal slope using least squares\n",
    "3. Calculates optimal intercept\n",
    "4. Minimizes prediction errors\n",
    "5. Stores learned parameters in the model\n",
    "\n",
    "**AFTER:**\n",
    "```python\n",
    "model.coef_ = [200.0]      # Learned slope: $200 per sq ft\n",
    "model.intercept_ = 50000   # Learned intercept: $50,000 base price\n",
    "```\n",
    "\n",
    "The model is now \"trained\" and ready to make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6790e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"‚úì Model trained successfully!\")\n",
    "print(\"\\nBehind the scenes, sklearn:\")\n",
    "print(\"  1. Calculated the optimal slope\")\n",
    "print(\"  2. Calculated the optimal intercept\")\n",
    "print(\"  3. Minimized prediction errors\")\n",
    "print(\"\\nAll in one line of code! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524fbb0",
   "metadata": {},
   "source": [
    "## Inspect What the Model Learned üîç\n",
    "\n",
    "After training, we can see what the model learned from the data.\n",
    "\n",
    "Every sklearn model stores learned values in **attributes** (variables ending with `_`):\n",
    "\n",
    "```python\n",
    "model.intercept_  # The y-intercept (base value)\n",
    "model.coef_       # Coefficients (slopes) - one per feature\n",
    "```\n",
    "\n",
    "### Understanding the Values:\n",
    "\n",
    "**Intercept:** The Y value when X = 0 (starting point of the line)\n",
    "- Example: `intercept_ = 50000` means base price is $50,000\n",
    "- In context: \"A house with 0 sq ft would theoretically cost $50,000\"\n",
    "\n",
    "**Coefficient:** How much Y changes when X increases by 1 (slope of the line)\n",
    "- Example: `coef_ = 200` means each square foot adds $200\n",
    "- In context: \"Each additional square foot increases price by $200\"\n",
    "\n",
    "### Why the underscore `_`?\n",
    "\n",
    "In sklearn:\n",
    "- **No underscore** = Settings you provide (before training)\n",
    "- **With underscore `_`** = Values learned from data (after training)\n",
    "\n",
    "This convention helps you distinguish between what you set and what the model learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c179d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get learned parameters\n",
    "slope = model.coef_[0]  # Coefficient (slope)\n",
    "intercept = model.intercept_  # Intercept\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Slope (coefficient):  ${slope:.2f} per sq ft\")\n",
    "print(f\"Intercept (base):     ${intercept:,.2f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìê Learned Formula:\")\n",
    "print(f\"Price = {slope:.2f} √ó Square_Feet + {intercept:,.2f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ Each additional square foot adds ${slope:.2f} to the price\")\n",
    "print(f\"‚Ä¢ Base price (0 sq ft) would be ${intercept:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4325f39",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions üîÆ\n",
    "\n",
    "Now our trained model can predict prices for any square footage!\n",
    "\n",
    "### How `.predict()` Works:\n",
    "\n",
    "```\n",
    "Input: Square footage (X)\n",
    "  ‚Üì\n",
    "Model applies learned formula:\n",
    "  Price = (slope √ó Square_Feet) + intercept\n",
    "  ‚Üì\n",
    "Output: Predicted price\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "new_house = [[2200]]           # 2200 square feet (must be 2D!)\n",
    "prediction = model.predict(new_house)\n",
    "\n",
    "# Behind the scenes:\n",
    "# Price = 200 √ó 2200 + 50000\n",
    "# Price = 440000 + 50000\n",
    "# Price = 490000  ‚Üí $490,000\n",
    "```\n",
    "\n",
    "**Key Point:** The input must be 2D, just like when we trained! Use `[[value]]` not `[value]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for our original data\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Square_Feet': X['Square_Feet'],\n",
    "    'Actual_Price': y,\n",
    "    'Predicted_Price': predictions,\n",
    "    'Error': y - predictions\n",
    "})\n",
    "\n",
    "print(\"Predictions vs Actual:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison)\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úì Perfect predictions! (Because data is perfectly linear)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f05cc",
   "metadata": {},
   "source": [
    "## Predict for a New House\n",
    "\n",
    "Let's predict the price for a house we haven't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New house: 2200 square feet\n",
    "new_house_sqft = 2200\n",
    "\n",
    "# Need to format as 2D array for sklearn\n",
    "new_house_X = [[new_house_sqft]]  # Double brackets for 2D\n",
    "\n",
    "# Predict\n",
    "predicted_price = model.predict(new_house_X)[0]  # [0] gets the single value\n",
    "\n",
    "print(f\"üè† New House: {new_house_sqft:,} square feet\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üí∞ Predicted Price: ${predicted_price:,.2f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show the calculation\n",
    "manual_calc = slope * new_house_sqft + intercept\n",
    "print(f\"\\nüìê Calculation:\")\n",
    "print(f\"{slope:.2f} √ó {new_house_sqft:,} + {intercept:,.2f} = ${manual_calc:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667e453",
   "metadata": {},
   "source": [
    "## Visualize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8cb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual data points\n",
    "plt.scatter(X, y, color='blue', s=100, alpha=0.6, label='Actual Prices', zorder=3)\n",
    "\n",
    "# Plot regression line\n",
    "x_line = np.array([[X['Square_Feet'].min()], [X['Square_Feet'].max()]])\n",
    "y_line = model.predict(x_line)\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=3, label='Sklearn Model', zorder=2)\n",
    "\n",
    "# Plot prediction for new house\n",
    "plt.scatter(new_house_sqft, predicted_price, color='green', s=200, \n",
    "            marker='*', label='New House Prediction', zorder=4, edgecolors='black')\n",
    "\n",
    "# Labels and styling\n",
    "plt.xlabel('Square Feet', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontsize=12, fontweight='bold')\n",
    "plt.title('Linear Regression with Scikit-Learn', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Model fits the data perfectly!\")\n",
    "print(\"‚úì Green star shows our new prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83002d38",
   "metadata": {},
   "source": [
    "# Part 2: Train-Test Split with Sklearn ‚úÇÔ∏è\n",
    "\n",
    "## Why Split Data?\n",
    "\n",
    "**Remember the golden rule:** Never test on your training data!\n",
    "\n",
    "Testing on training data is like:\n",
    "- üìñ Studying WITH the exam questions in front of you\n",
    "- üéÆ Playing a video game with a walkthrough\n",
    "- üèÉ Running a race where you already know the route\n",
    "\n",
    "You'll get great results, but it doesn't prove you actually learned anything useful!\n",
    "\n",
    "### The Problem:\n",
    "\n",
    "**Bad Approach (no split):**\n",
    "```\n",
    "All Data ‚Üí Train model ‚Üí Test on same data ‚Üí \"Perfect\" scores ‚úì\n",
    "                                              But will it work on new data? ‚ùå\n",
    "```\n",
    "\n",
    "**Good Approach (train-test split):**\n",
    "```\n",
    "All Data ‚Üí Split into Train (80%) & Test (20%)\n",
    "        ‚Üí Train on training set only\n",
    "        ‚Üí Test on unseen test data ‚Üí Realistic performance ‚úì\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## The Sklearn Way\n",
    "\n",
    "**From scratch:** We wrote ~10 lines to shuffle and split data.\n",
    "\n",
    "**With sklearn:** ONE line does it all! üéâ\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "```\n",
    "\n",
    "**This ONE function:**\n",
    "- Shuffles the data randomly\n",
    "- Splits into train and test sets\n",
    "- Returns 4 arrays (X_train, X_test, y_train, y_test)\n",
    "- Maintains proper correspondence between features and targets\n",
    "\n",
    "---\n",
    "\n",
    "## Create a Larger Dataset\n",
    "\n",
    "Let's create a more realistic dataset with some noise (variation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create 100 houses\n",
    "n_samples = 100\n",
    "\n",
    "# Generate data\n",
    "square_feet_large = np.random.randint(1000, 4000, n_samples)\n",
    "noise = np.random.normal(0, 30000, n_samples)  # Add realistic variation\n",
    "prices_large = (200 * square_feet_large) + 50000 + noise\n",
    "\n",
    "# Create DataFrame\n",
    "df_large = pd.DataFrame({\n",
    "    'Square_Feet': square_feet_large,\n",
    "    'Price': prices_large\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {len(df_large)} houses!\")\n",
    "print(\"\\nFirst 10 houses:\")\n",
    "print(df_large.head(10))\n",
    "print(f\"\\nData shape: {df_large.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391df6a",
   "metadata": {},
   "source": [
    "## Visualize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35419e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_large['Square_Feet'], df_large['Price'], alpha=0.5, s=50)\n",
    "plt.xlabel('Square Feet', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontsize=12, fontweight='bold')\n",
    "plt.title('House Prices vs Square Footage (100 Houses)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Data has scatter (noise), like real-world data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ce8e9",
   "metadata": {},
   "source": [
    "## Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff63fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X_large = df_large[['Square_Feet']]\n",
    "y_large = df_large['Price']\n",
    "\n",
    "print(f\"Features (X) shape: {X_large.shape}\")\n",
    "print(f\"Target (y) shape: {y_large.shape}\")\n",
    "print(\"\\n‚úì Data ready for train-test split!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e69ecc",
   "metadata": {},
   "source": [
    "## Perform Train-Test Split üé≤\n",
    "\n",
    "This one line does everything we need:\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "### Breaking It Down:\n",
    "\n",
    "**Inputs:**\n",
    "- `X` - All features (100%)\n",
    "- `y` - All targets (100%)\n",
    "- `test_size=0.2` - Keep 20% for testing (0.2 = 20%)\n",
    "- `random_state=42` - Random seed for reproducibility\n",
    "\n",
    "**Outputs (4 arrays):**\n",
    "- `X_train` - Features for training (80%)\n",
    "- `X_test` - Features for testing (20%)\n",
    "- `y_train` - Targets for training (80%)\n",
    "- `y_test` - Targets for testing (20%)\n",
    "\n",
    "### Understanding `test_size`:\n",
    "\n",
    "Common practice is to use 20-30% for testing:\n",
    "```python\n",
    "test_size=0.2   # 20% test, 80% train (most common)\n",
    "test_size=0.25  # 25% test, 75% train\n",
    "test_size=0.3   # 30% test, 70% train\n",
    "```\n",
    "\n",
    "**Rule of thumb:** More training data is usually better, but you need enough test data to evaluate reliably.\n",
    "\n",
    "### Understanding `random_state`:\n",
    "\n",
    "**Without random_state:**\n",
    "```python\n",
    "# Run 1: Random houses [5, 12, 23, 45, ...] go to test set\n",
    "# Run 2: Different houses [3, 8, 19, 41, ...] go to test set ‚ùå Not reproducible!\n",
    "```\n",
    "\n",
    "**With random_state:**\n",
    "```python\n",
    "random_state=42  # Or any number\n",
    "# Run 1: Houses [5, 12, 23, 45, ...] go to test set\n",
    "# Run 2: Same houses [5, 12, 23, 45, ...] go to test set ‚úì Reproducible!\n",
    "```\n",
    "\n",
    "**Why 42?** It's a convention from \"Hitchhiker's Guide to the Galaxy\" - any number works, but 42 is popular!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4106e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_large, \n",
    "    y_large, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42     # For reproducibility\n",
    ")\n",
    "\n",
    "print(\"‚úì Train-Test Split Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original dataset:  {len(X_large)} houses\")\n",
    "print(f\"Training set:      {len(X_train)} houses ({len(X_train)/len(X_large)*100:.0f}%)\")\n",
    "print(f\"Test set:          {len(X_test)} houses ({len(X_test)/len(X_large)*100:.0f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüí° What just happened:\")\n",
    "print(\"‚Ä¢ X_train, y_train ‚Üí Model will learn from these\")\n",
    "print(\"‚Ä¢ X_test, y_test ‚Üí Model will be tested on these (unseen!)\")\n",
    "print(\"‚Ä¢ random_state=42 ‚Üí Makes results reproducible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ef4af",
   "metadata": {},
   "source": [
    "## Train Model on Training Data Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "model_split = LinearRegression()\n",
    "model_split.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úì Model trained on training data!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Learned Slope:     ${model_split.coef_[0]:.2f} per sq ft\")\n",
    "print(f\"Learned Intercept: ${model_split.intercept_:,.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nModel has NOT seen the test data yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b7cf0",
   "metadata": {},
   "source": [
    "# Part 3: Model Evaluation with Sklearn Metrics üìä\n",
    "\n",
    "### The Easy Way\n",
    "Remember calculating metrics from scratch? Let's compare:\n",
    "\n",
    "\n",
    "### From Scratch (Manual):\n",
    "\n",
    "```python\n",
    "# MAE - Mean Absolute Error\n",
    "errors = y_true - y_pred\n",
    "mae = np.mean(np.abs(errors))\n",
    "\n",
    "# MSE - Mean Squared Error\n",
    "mse = np.mean(errors ** 2)\n",
    "\n",
    "# RMSE - Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# R¬≤ - Coefficient of Determination\n",
    "ss_total = np.sum((y - y.mean()) ** 2)\n",
    "ss_residual = np.sum(errors ** 2)\n",
    "r2 = 1 - (ss_residual / ss_total)\n",
    "```\n",
    "\n",
    "### Sklearn Approach (Simple):\n",
    "\n",
    "```python\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)  # Or mean_squared_error(y_true, y_pred, squared=False)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "**Much easier!** One function call per metric. ‚ú®\n",
    "\n",
    "---\n",
    "\n",
    "## Understanding the Metrics\n",
    "\n",
    "### 1. MAE (Mean Absolute Error)\n",
    "\n",
    "**What it measures:** Average size of errors (in original units)\n",
    "\n",
    "```\n",
    "MAE = Average of |actual - predicted|\n",
    "```\n",
    "\n",
    "**Example:** If MAE = $25,000\n",
    "- \"On average, predictions are off by $25,000\"\n",
    "- Could be $25k too high or $25k too low\n",
    "\n",
    "**Lower is better!** MAE = 0 means perfect predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. MSE (Mean Squared Error)\n",
    "\n",
    "**What it measures:** Average of squared errors\n",
    "\n",
    "```\n",
    "MSE = Average of (actual - predicted)¬≤\n",
    "```\n",
    "\n",
    "**Why square the errors?**\n",
    "- Makes all errors positive (no cancellation)\n",
    "- Penalizes large errors MORE than small errors\n",
    "- Example: One $20k error hurts more than two $10k errors\n",
    "\n",
    "**Downside:** Units are squared ($¬≤), harder to interpret\n",
    "\n",
    "**Lower is better!**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. RMSE (Root Mean Squared Error)\n",
    "\n",
    "**What it measures:** Square root of MSE\n",
    "\n",
    "```\n",
    "RMSE = ‚àöMSE\n",
    "```\n",
    "\n",
    "**Why it's popular:**\n",
    "- Same units as original target (dollars, not dollars¬≤)\n",
    "- Still penalizes large errors\n",
    "- Most commonly used metric in regression\n",
    "\n",
    "**Example:** If RMSE = $28,000\n",
    "- \"Typical prediction error is around $28,000\"\n",
    "\n",
    "**Lower is better!**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. R¬≤ (R-Squared / Coefficient of Determination)\n",
    "\n",
    "**What it measures:** Percentage of variance in Y explained by the model\n",
    "\n",
    "```\n",
    "R¬≤ = 1 - (unexplained variance / total variance)\n",
    "```\n",
    "\n",
    "**Scale:** 0 to 1 (can be negative if model is terrible)\n",
    "\n",
    "**Interpretation:**\n",
    "- **R¬≤ = 1.0** ‚Üí Perfect predictions! Every point on the line! üéØ\n",
    "- **R¬≤ = 0.9** ‚Üí Excellent! Model explains 90% of variance\n",
    "- **R¬≤ = 0.7** ‚Üí Good! Model explains 70% of variance\n",
    "- **R¬≤ = 0.5** ‚Üí Okay. Model explains 50% of variance\n",
    "- **R¬≤ = 0.0** ‚Üí Useless. No better than predicting the mean\n",
    "- **R¬≤ < 0** ‚Üí Worse than useless! Model is actually harmful\n",
    "\n",
    "**Higher is better!** Maximum is 1.0\n",
    "\n",
    "**Example:** If R¬≤ = 0.85\n",
    "- \"Our model explains 85% of the variance in house prices\"\n",
    "- \"15% is due to factors we haven't captured\"\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluate on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training data\n",
    "y_train_pred = model_split.predict(X_train)\n",
    "\n",
    "# Calculate metrics using sklearn\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)  # Or use mean_squared_error with squared=False\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"üìä TRAINING SET PERFORMANCE:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE (Mean Absolute Error):       ${train_mae:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error):  ${train_rmse:,.2f}\")\n",
    "print(f\"R¬≤ Score:                        {train_r2:.4f} ({train_r2*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ On average, predictions are off by ${train_mae:,.0f}\")\n",
    "print(f\"‚Ä¢ Model explains {train_r2*100:.1f}% of price variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f17ee0",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data (The Real Test!) üéØ\n",
    "\n",
    "This tells us how well the model works on **new, unseen data**.\n",
    "\n",
    "This is what actually matters in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ae6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_test_pred = model_split.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"üéØ TEST SET PERFORMANCE (Unseen Data):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE (Mean Absolute Error):       ${test_mae:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error):  ${test_rmse:,.2f}\")\n",
    "print(f\"R¬≤ Score:                        {test_r2:.4f} ({test_r2*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüí° This is what really matters!\")\n",
    "print(\"   Test performance shows how the model will work in the real world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9a0d4",
   "metadata": {},
   "source": [
    "## Compare Training vs Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'RMSE', 'R¬≤'],\n",
    "    'Training': [f'${train_mae:,.2f}', f'${train_rmse:,.2f}', f'{train_r2:.4f}'],\n",
    "    'Test': [f'${test_mae:,.2f}', f'${test_rmse:,.2f}', f'{test_r2:.4f}']\n",
    "})\n",
    "\n",
    "print(\"üìä Training vs Test Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze the difference\n",
    "r2_diff = abs(train_r2 - test_r2)\n",
    "\n",
    "if r2_diff < 0.05:\n",
    "    print(\"\\n‚úì Excellent! Training and test scores are similar\")\n",
    "    print(\"  ‚Üí Model generalizes well to new data\")\n",
    "elif r2_diff < 0.1:\n",
    "    print(\"\\n‚óã Good! Scores are reasonably close\")\n",
    "    print(\"  ‚Üí Model is performing acceptably\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Warning: Large gap between training and test\")\n",
    "    print(\"  ‚Üí Possible overfitting or small test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b98175",
   "metadata": {},
   "source": [
    "## Visualize Predictions on Both Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training data plot\n",
    "ax1.scatter(X_train, y_train, alpha=0.5, s=30, label='Actual Prices')\n",
    "x_line_train = np.array([[X_train.values.min()], [X_train.values.max()]])\n",
    "y_line_train = model_split.predict(x_line_train)\n",
    "ax1.plot(x_line_train, y_line_train, 'r-', linewidth=3, label='Model')\n",
    "ax1.set_xlabel('Square Feet', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Price ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Training Data (R¬≤ = {train_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Test data plot\n",
    "ax2.scatter(X_test, y_test, alpha=0.5, s=30, color='orange', label='Actual Prices')\n",
    "x_line_test = np.array([[X_test.values.min()], [X_test.values.max()]])\n",
    "y_line_test = model_split.predict(x_line_test)\n",
    "ax2.plot(x_line_test, y_line_test, 'r-', linewidth=3, label='Model')\n",
    "ax2.set_xlabel('Square Feet', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Price ($)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Test Data (R¬≤ = {test_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Model performs well on both training and test data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf27e0d",
   "metadata": {},
   "source": [
    "# Part 4: Multiple Features with Sklearn üí™\n",
    "\n",
    "This is where sklearn REALLY shines!\n",
    "\n",
    "\n",
    "### From Scratch vs Sklearn:\n",
    "\n",
    "**From Scratch (Multiple Features):**\n",
    "```python\n",
    "# Add column of 1s for intercept\n",
    "X_with_ones = np.column_stack([np.ones(len(X)), X])\n",
    "\n",
    "# Matrix multiplication\n",
    "XTX = X_with_ones.T @ X_with_ones\n",
    "\n",
    "# Matrix inversion (complex!)\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "# More matrix operations\n",
    "XTy = X_with_ones.T @ y\n",
    "\n",
    "# Final calculation\n",
    "weights = XTX_inv @ XTy\n",
    "\n",
    "# üò´ Complex! Error-prone! Hard to understand!\n",
    "```\n",
    "\n",
    "**With Sklearn:**\n",
    "```python\n",
    "model.fit(X, y)  # That's it! üéâ\n",
    "\n",
    "# üòÑ Same line! Works with 1, 10, or 1000 features!\n",
    "```\n",
    "\n",
    "### The Beautiful Part:\n",
    "\n",
    "The API is **identical** regardless of feature count:\n",
    "\n",
    "```python\n",
    "# 1 Feature:\n",
    "model.fit(X, y)  # Works! ‚úì\n",
    "\n",
    "# 10 Features:\n",
    "model.fit(X, y)  # Works! ‚úì\n",
    "\n",
    "# 100 Features:\n",
    "model.fit(X, y)  # Works! ‚úì\n",
    "\n",
    "# 1000 Features:\n",
    "model.fit(X, y)  # Still works! ‚úì\n",
    "```\n",
    "\n",
    "**This is brilliant design!** Learn it once, use it everywhere.\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World House Prices üè°\n",
    "\n",
    "In reality, house prices depend on MANY factors:\n",
    "\n",
    "```\n",
    "House Price = f(\n",
    "    Square Footage,      ‚Üê Size of the house\n",
    "    Number of Bedrooms,  ‚Üê Sleeping capacity\n",
    "    Number of Bathrooms, ‚Üê Convenience\n",
    "    Age of House,        ‚Üê Condition\n",
    "    Location,            ‚Üê Neighborhood quality\n",
    "    School District,     ‚Üê Education quality\n",
    "    Lot Size,            ‚Üê Land area\n",
    "    Amenities,           ‚Üê Pool, garage, etc.\n",
    "    ... and more!\n",
    ")\n",
    "```\n",
    "\n",
    "**One feature (square feet) is useful, but limited.**\n",
    "\n",
    "**Multiple features give a more complete picture!**\n",
    "\n",
    "### The Formula Extends:\n",
    "\n",
    "**One feature:**\n",
    "```\n",
    "Price = (w‚ÇÅ √ó Square_Feet) + intercept\n",
    "```\n",
    "\n",
    "**Multiple features:**\n",
    "```\n",
    "Price = (w‚ÇÅ √ó Square_Feet) + \n",
    "        (w‚ÇÇ √ó Bedrooms) + \n",
    "        (w‚ÇÉ √ó Bathrooms) + \n",
    "        intercept\n",
    "```\n",
    "\n",
    "Where: w‚ÇÅ, w‚ÇÇ, w‚ÇÉ = Weights (importance) of each feature\n",
    "\n",
    "**Example calculation:**\n",
    "```\n",
    "Price = (150 √ó 2500) +     # $150 per square foot\n",
    "        (20000 √ó 4) +      # $20,000 per bedroom\n",
    "        (15000 √ó 2) +      # $15,000 per bathroom\n",
    "        50000              # Base price\n",
    "      = $375,000 + $80,000 + $30,000 + $50,000\n",
    "      = $535,000\n",
    "```\n",
    "\n",
    "Let's create a multi-feature dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Generate features\n",
    "square_feet_multi = np.random.randint(1000, 4000, n)\n",
    "bedrooms = np.random.randint(1, 6, n)\n",
    "bathrooms = np.random.randint(1, 4, n)\n",
    "\n",
    "# Generate prices (true relationship + noise)\n",
    "noise_multi = np.random.normal(0, 30000, n)\n",
    "prices_multi = (150 * square_feet_multi + \n",
    "                20000 * bedrooms + \n",
    "                15000 * bathrooms + \n",
    "                50000 + \n",
    "                noise_multi)\n",
    "\n",
    "# Create DataFrame\n",
    "df_multi = pd.DataFrame({\n",
    "    'Square_Feet': square_feet_multi,\n",
    "    'Bedrooms': bedrooms,\n",
    "    'Bathrooms': bathrooms,\n",
    "    'Price': prices_multi\n",
    "})\n",
    "\n",
    "print(\"Dataset with Multiple Features:\")\n",
    "print(\"=\"*70)\n",
    "print(df_multi.head(10))\n",
    "print(\"\\nShape:\", df_multi.shape)\n",
    "print(\"\\nFeatures: Square_Feet, Bedrooms, Bathrooms\")\n",
    "print(\"Target: Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3be00a",
   "metadata": {},
   "source": [
    "## Prepare Multi-Feature Data\n",
    "\n",
    "**Now X has 3 columns instead of 1!**\n",
    "\n",
    "### Visual Comparison:\n",
    "\n",
    "**Before (One Feature):**\n",
    "```python\n",
    "X = df[['Square_Feet']]\n",
    "# Shape: (100, 1) - 100 houses, 1 feature\n",
    "```\n",
    "\n",
    "**Now (Three Features):**\n",
    "```python\n",
    "X = df[['Square_Feet', 'Bedrooms', 'Bathrooms']]\n",
    "# Shape: (100, 3) - 100 houses, 3 features\n",
    "```\n",
    "\n",
    "### The Beautiful Part:\n",
    "\n",
    "**Same sklearn code works for both!**\n",
    "\n",
    "```python\n",
    "# One feature:\n",
    "X = df[['Square_Feet']]\n",
    "model.fit(X, y)  # Works! ‚úì\n",
    "\n",
    "# Multiple features:\n",
    "X = df[['Square_Feet', 'Bedrooms', 'Bathrooms']]\n",
    "model.fit(X, y)  # Also works! ‚úì  Same code!\n",
    "```\n",
    "\n",
    "No code changes needed - sklearn handles it automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ca03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (all 3 columns)\n",
    "X_multi = df_multi[['Square_Feet', 'Bedrooms', 'Bathrooms']]\n",
    "\n",
    "# Prepare target\n",
    "y_multi = df_multi['Price']\n",
    "\n",
    "print(\"Feature Matrix (X):\")\n",
    "print(X_multi.head())\n",
    "print(f\"\\nShape: {X_multi.shape} - (100 samples, 3 features)\")\n",
    "\n",
    "print(\"\\n‚úì Ready for multi-feature regression!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1439791",
   "metadata": {},
   "source": [
    "## Train-Test Split for Multi-Feature Data\n",
    "\n",
    "Same function works with any number of features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc413e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, \n",
    "    y_multi, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úì Multi-feature data split complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set: {len(X_train_multi)} houses\")\n",
    "print(f\"Test set:     {len(X_test_multi)} houses\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEach sample has {X_train_multi.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b783d83",
   "metadata": {},
   "source": [
    "## Train Multi-Feature Model\n",
    "\n",
    "Exact same code as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c86f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "print(\"‚úì Multi-feature model trained!\")\n",
    "print(\"\\nNo matrix math required - sklearn handled it all! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc1573",
   "metadata": {},
   "source": [
    "## Inspect Multi-Feature Model Parameters üîç\n",
    "\n",
    "**Now we have 3 coefficients - one for each feature!**\n",
    "\n",
    "### Understanding Coefficients:\n",
    "\n",
    "**With one feature:**\n",
    "```python\n",
    "model.coef_ = [200]  # Just one number\n",
    "```\n",
    "\n",
    "**With multiple features:**\n",
    "```python\n",
    "model.coef_ = [150, 20000, 15000]  # Array of numbers\n",
    "                ‚Üë      ‚Üë      ‚Üë\n",
    "           sqft  bedrooms bathrooms\n",
    "```\n",
    "\n",
    "### The Formula:\n",
    "\n",
    "```\n",
    "Price = intercept + (coef[0] √ó sqft) + (coef[1] √ó beds) + (coef[2] √ó baths)\n",
    "```\n",
    "\n",
    "**Example calculation:**\n",
    "```\n",
    "Price = $50,000 + (150 √ó 2500) + (20000 √ó 4) + (15000 √ó 2)\n",
    "      = $50,000 + $375,000 + $80,000 + $30,000\n",
    "      = $535,000\n",
    "```\n",
    "\n",
    "### What Each Coefficient Means:\n",
    "\n",
    "**Coefficient 1 (Square Feet): $150**\n",
    "- \"Each additional square foot adds $150 to the price\"\n",
    "- *Holding bedrooms and bathrooms constant*\n",
    "- Going from 2000 to 2001 sqft ‚Üí +$150\n",
    "\n",
    "**Coefficient 2 (Bedrooms): $20,000**\n",
    "- \"Each additional bedroom adds $20,000 to the price\"\n",
    "- *Holding square feet and bathrooms constant*\n",
    "- Going from 3 to 4 bedrooms ‚Üí +$20,000\n",
    "\n",
    "**Coefficient 3 (Bathrooms): $15,000**\n",
    "- \"Each additional bathroom adds $15,000 to the price\"\n",
    "- *Holding other features constant*\n",
    "- Going from 2 to 3 bathrooms ‚Üí +$15,000\n",
    "\n",
    "**Key insight:** Each coefficient tells you the impact of ONE feature while keeping others constant. This is called \"all else being equal\" or *ceteris paribus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e21cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients (slopes)\n",
    "coefficients = model_multi.coef_\n",
    "intercept_multi = model_multi.intercept_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_multi.columns.tolist()\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Intercept (base price): ${intercept_multi:,.2f}\")\n",
    "print(\"\\nCoefficients (feature weights):\")\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"  {name:<15}: ${coef:,.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìê Learned Formula:\")\n",
    "print(f\"Price = ${intercept_multi:,.0f} + \")\n",
    "print(f\"        ({coefficients[0]:.2f} √ó Square_Feet) + \")\n",
    "print(f\"        ({coefficients[1]:,.2f} √ó Bedrooms) + \")\n",
    "print(f\"        ({coefficients[2]:,.2f} √ó Bathrooms)\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ Each square foot adds: ${coefficients[0]:.2f}\")\n",
    "print(f\"‚Ä¢ Each bedroom adds:     ${coefficients[1]:,.2f}\")\n",
    "print(f\"‚Ä¢ Each bathroom adds:    ${coefficients[2]:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e61e8",
   "metadata": {},
   "source": [
    "## Evaluate Multi-Feature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_train_pred_multi = model_multi.predict(X_train_multi)\n",
    "y_test_pred_multi = model_multi.predict(X_test_multi)\n",
    "\n",
    "# Training metrics\n",
    "train_mae_multi = mean_absolute_error(y_train_multi, y_train_pred_multi)\n",
    "train_rmse_multi = np.sqrt(mean_squared_error(y_train_multi, y_train_pred_multi))\n",
    "train_r2_multi = r2_score(y_train_multi, y_train_pred_multi)\n",
    "\n",
    "# Test metrics\n",
    "test_mae_multi = mean_absolute_error(y_test_multi, y_test_pred_multi)\n",
    "test_rmse_multi = np.sqrt(mean_squared_error(y_test_multi, y_test_pred_multi))\n",
    "test_r2_multi = r2_score(y_test_multi, y_test_pred_multi)\n",
    "\n",
    "print(\"üìä Multi-Feature Model Performance:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<20} {'Training':<25} {'Test':<25}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'MAE':<20} ${train_mae_multi:<24,.2f} ${test_mae_multi:<24,.2f}\")\n",
    "print(f\"{'RMSE':<20} ${train_rmse_multi:<24,.2f} ${test_rmse_multi:<24,.2f}\")\n",
    "print(f\"{'R¬≤':<20} {train_r2_multi:<24.4f} {test_r2_multi:<24.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(f\"‚Ä¢ Using 3 features gives R¬≤ = {test_r2_multi:.4f}\")\n",
    "print(\"‚Ä¢ More features often = better predictions!\")\n",
    "print(\"‚Ä¢ But be careful not to add too many (overfitting risk)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ab022",
   "metadata": {},
   "source": [
    "## Predict for a New House (Multiple Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c96d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New house specifications\n",
    "new_house = {\n",
    "    'Square_Feet': 2500,\n",
    "    'Bedrooms': 4,\n",
    "    'Bathrooms': 2\n",
    "}\n",
    "\n",
    "# Convert to DataFrame (sklearn prefers this format)\n",
    "new_house_df = pd.DataFrame([new_house])\n",
    "\n",
    "# Predict\n",
    "predicted_price_multi = model_multi.predict(new_house_df)[0]\n",
    "\n",
    "print(\"üè† New House Specifications:\")\n",
    "print(\"=\"*60)\n",
    "for feature, value in new_house.items():\n",
    "    print(f\"  {feature:<15}: {value:,}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüí∞ Predicted Price: ${predicted_price_multi:,.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show breakdown\n",
    "print(\"\\nüìê Price Breakdown:\")\n",
    "print(f\"  Base price:       ${intercept_multi:,.2f}\")\n",
    "print(f\"  + Square footage: ${coefficients[0] * new_house['Square_Feet']:,.2f}\")\n",
    "print(f\"  + Bedrooms:       ${coefficients[1] * new_house['Bedrooms']:,.2f}\")\n",
    "print(f\"  + Bathrooms:      ${coefficients[2] * new_house['Bathrooms']:,.2f}\")\n",
    "print(f\"  {'-'*40}\")\n",
    "print(f\"  Total:            ${predicted_price_multi:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a11827",
   "metadata": {},
   "source": [
    "## Batch Predictions üè≠\n",
    "\n",
    "**One of sklearn's superpowers: Predict for MANY samples at once!**\n",
    "\n",
    "### Real-World Application:\n",
    "\n",
    "**Scenario:** Real estate website\n",
    "- User searches for houses\n",
    "- 100 matching houses found\n",
    "- Need to predict prices for all of them\n",
    "\n",
    "**Inefficient approach:**\n",
    "```python\n",
    "# Predict one at a time (slow!)\n",
    "pred1 = model.predict([[1500, 2, 1]])\n",
    "pred2 = model.predict([[2000, 3, 2]])\n",
    "pred3 = model.predict([[2800, 4, 2]])\n",
    "# ... repeat 97 more times üò´\n",
    "```\n",
    "\n",
    "**Efficient approach (batch prediction):**\n",
    "```python\n",
    "# Predict all at once (fast!)\n",
    "houses = [[1500, 2, 1],\n",
    "          [2000, 3, 2],\n",
    "          [2800, 4, 2],\n",
    "          ...]  # All 100 houses\n",
    "predictions = model.predict(houses)  # One call! ‚ö°\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Faster (optimized internally)\n",
    "- Cleaner code\n",
    "- Less error-prone\n",
    "- Professional approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7462179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple new houses\n",
    "new_houses = pd.DataFrame({\n",
    "    'Square_Feet': [1500, 2000, 2800, 3200],\n",
    "    'Bedrooms': [2, 3, 4, 5],\n",
    "    'Bathrooms': [1, 2, 2, 3]\n",
    "})\n",
    "\n",
    "# Predict for all at once\n",
    "predictions_batch = model_multi.predict(new_houses)\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "new_houses['Predicted_Price'] = predictions_batch\n",
    "\n",
    "print(\"üèòÔ∏è Batch Predictions for Multiple Houses:\")\n",
    "print(\"=\"*70)\n",
    "print(new_houses.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úì Predicted prices for all 4 houses in one call!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381627d3",
   "metadata": {},
   "source": [
    "# Part 5: The Sklearn Workflow - Complete Picture üé®\n",
    "\n",
    "## The Universal Pattern\n",
    "\n",
    "This is the **most important concept** in sklearn:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ         SKLEARN WORKFLOW                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  1. IMPORT                              ‚îÇ\n",
    "‚îÇ     from sklearn.X import ModelName     ‚îÇ\n",
    "‚îÇ                                         ‚îÇ\n",
    "‚îÇ  2. CREATE                              ‚îÇ\n",
    "‚îÇ     model = ModelName()                 ‚îÇ\n",
    "‚îÇ                                         ‚îÇ\n",
    "‚îÇ  3. FIT (Train)                         ‚îÇ\n",
    "‚îÇ     model.fit(X_train, y_train)         ‚îÇ\n",
    "‚îÇ                                         ‚îÇ\n",
    "‚îÇ  4. PREDICT                             ‚îÇ\n",
    "‚îÇ     predictions = model.predict(X_test) ‚îÇ\n",
    "‚îÇ                                         ‚îÇ\n",
    "‚îÇ  5. EVALUATE                            ‚îÇ\n",
    "‚îÇ     score = model.score(X_test, y_test) ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### This Works For All Models:\n",
    "\n",
    "- ‚úì Linear Regression (what we learned)\n",
    "- ‚úì Logistic Regression\n",
    "- ‚úì Decision Trees\n",
    "- ‚úì Random Forests\n",
    "- ‚úì Support Vector Machines\n",
    "- ‚úì Gradient Boosting\n",
    "- ‚úì Neural Networks\n",
    "- ‚úì And 100+ more algorithms!\n",
    "\n",
    "**Same workflow! Just change the model name.** üéØ\n",
    "\n",
    "This is why sklearn is so powerful - learn the pattern once, apply it everywhere.\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Example - All Steps Together\n",
    "\n",
    "Here's a **complete sklearn program** in one place:\n",
    "\n",
    "```python\n",
    "# Step 1: Import everything you need\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Step 2: Prepare your data\n",
    "X = df[['feature1', 'feature2', 'feature3']]\n",
    "y = df['target']\n",
    "\n",
    "# Step 3: Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate performance\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"MAE: ${mae:,.2f}\")\n",
    "print(f\"R¬≤: {r2:.4f}\")\n",
    "```\n",
    "\n",
    "**That's it!** This is the template for 90% of ML projects! üìã\n",
    "\n",
    "Copy this template, change the model name, and you're ready to try different algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8815e71",
   "metadata": {},
   "source": [
    "# Final Summary üéì\n",
    "\n",
    "## What We Accomplished Today\n",
    "\n",
    "Congratulations! You just learned the **professional way** to do machine learning!\n",
    "\n",
    "### 1. Linear Regression with Sklearn ‚úì\n",
    "- The 3-step workflow (Create ‚Üí Fit ‚Üí Predict)\n",
    "- Creating and training models in seconds\n",
    "- Making predictions for new data\n",
    "- Inspecting learned parameters (slope, intercept)\n",
    "\n",
    "### 2. Train-Test Split ‚úì\n",
    "- Why splitting data is critical (avoid overfitting!)\n",
    "- How to split data in ONE line of code\n",
    "- Understanding `test_size` and `random_state`\n",
    "- Testing on unseen data for realistic performance\n",
    "\n",
    "### 3. Model Evaluation ‚úì\n",
    "- Calculate MAE, RMSE, R¬≤ with simple function calls\n",
    "- What each metric means and when to use it\n",
    "- Comparing training vs test performance\n",
    "- Detecting overfitting (big gap between train and test)\n",
    "\n",
    "### 4. Multiple Features ‚úì\n",
    "- Same code works for 1, 10, or 1000 features\n",
    "- Preparing multi-feature data\n",
    "- Interpreting multiple coefficients\n",
    "- Making batch predictions efficiently\n",
    "\n",
    "---\n",
    "\n",
    "## From Scratch vs Sklearn - The Comparison\n",
    "\n",
    "| Task | From Scratch | Sklearn | Time Saved |\n",
    "|------|-------------|---------|------------|\n",
    "| **Linear Regression** | ~20 lines of formulas | `model.fit(X, y)` | 95% ‚ö° |\n",
    "| **Train-Test Split** | ~10 lines of code | `train_test_split(X, y)` | 90% ‚ö° |\n",
    "| **Calculate MAE** | Manual formula | `mean_absolute_error(...)` | 80% ‚ö° |\n",
    "| **Calculate R¬≤** | Complex formula | `r2_score(...)` | 85% ‚ö° |\n",
    "| **Multiple Features** | Matrix algebra (~30 lines) | `model.fit(X, y)` | 98% ‚ö° |\n",
    "\n",
    "**Average time saved: ~90%!**\n",
    "\n",
    "But more importantly, sklearn code is:\n",
    "- More readable\n",
    "- Less error-prone\n",
    "- Battle-tested by millions\n",
    "- Production-ready\n",
    "\n",
    "---\n",
    "\n",
    "## Why Learn Both?\n",
    "\n",
    "### From Scratch Approach üß†\n",
    "\n",
    "**Benefits:**\n",
    "- Understand fundamentals deeply\n",
    "- Know what's happening \"under the hood\"\n",
    "- Better debugging when things go wrong\n",
    "- Explain concepts to non-technical people\n",
    "- Understand limitations and edge cases\n",
    "\n",
    "**When to use:**\n",
    "- Learning and education\n",
    "- Implementing custom algorithms\n",
    "- Research and experimentation\n",
    "\n",
    "### Sklearn Approach üöÄ\n",
    "\n",
    "**Benefits:**\n",
    "- Fast and efficient\n",
    "- Tested and reliable (used by millions!)\n",
    "- Industry standard (what companies use)\n",
    "- Production-ready code\n",
    "- Access to 100+ algorithms\n",
    "- Active community and documentation\n",
    "\n",
    "**When to use:**\n",
    "- Real-world projects\n",
    "- Production systems\n",
    "- Quick prototyping\n",
    "- Business applications\n",
    "- When you need results fast\n",
    "\n",
    "**You now have BOTH!** This makes you a **complete** ML practitioner! üí™\n",
    "---\n",
    "\n",
    "## Resources üìö\n",
    "\n",
    "### Official Documentation:\n",
    "- **Sklearn Docs:** https://scikit-learn.org/\n",
    "- **User Guide:** https://scikit-learn.org/stable/user_guide.html\n",
    "- **Examples Gallery:** https://scikit-learn.org/stable/auto_examples/\n",
    "\n",
    "### Practice Platforms:\n",
    "- **Kaggle Learn:** Free interactive ML courses\n",
    "- **Kaggle Competitions:** Practice on real problems\n",
    "- **Google Colab:** Free GPU for experimentation\n",
    "\n",
    "---\n",
    "\n",
    "## You Did It! üéâ\n",
    "\n",
    "You went from manually calculating slopes to using professional ML tools.\n",
    "\n",
    "**That's HUGE progress!**\n",
    "\n",
    "**Key takeaways:**\n",
    "- You understand the fundamentals (from scratch)\n",
    "- You can use professional tools (sklearn)\n",
    "- You know the workflow (create ‚Üí fit ‚Üí predict ‚Üí evaluate)\n",
    "- You're ready for real projects!\n",
    "\n",
    "**Now go build something amazing!** üöÄ\n",
    "\n",
    "**Keep learning! Keep coding! Keep growing!**\n",
    "\n",
    "Happy Learning! üí°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc0a7c",
   "metadata": {},
   "source": [
    "By Abdulellah Mojalled : [linkedin](https://www.linkedin.com/in/abdulellah-mojalled/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72178f26",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c4629",
   "metadata": {},
   "source": [
    "## Extra Tips: Best Practices for Using Sklearn ‚úÖ\n",
    "\n",
    "### 1. Always Split Your Data\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "This prevents overfitting and gives you honest performance estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Train ONLY on Training Data\n",
    "\n",
    "**Do this:**\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "**Not this:**\n",
    "\n",
    "    model.fit(X, y)  # Don't use all your data!\n",
    "\n",
    "Your model needs to see fresh data at test time, not data it's already seen.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Evaluate on Test Data\n",
    "\n",
    "**Right:**\n",
    "\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "**Wrong:**\n",
    "\n",
    "    train_score = model.score(X_train, y_train)  # Too optimistic\n",
    "\n",
    "Test performance is what actually matters.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Use Multiple Metrics\n",
    "\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "Each metric shows something different about your model.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Compare Training vs Test Performance\n",
    "\n",
    "    train_r2 = model.score(X_train, y_train)\n",
    "    test_r2 = model.score(X_test, y_test)\n",
    "    \n",
    "    if abs(train_r2 - test_r2) > 0.1:\n",
    "        print(\"Warning: Possible overfitting!\")\n",
    "\n",
    "Big gap between training and test scores? Your model memorized instead of learned.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Use Consistent Random States\n",
    "\n",
    "    train_test_split(X, y, random_state=42)\n",
    "\n",
    "Makes your results reproducible.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Check Your Data Shapes\n",
    "\n",
    "    print(f\"X shape: {X.shape}\")  # Should be (n_samples, n_features)\n",
    "    print(f\"y shape: {y.shape}\")  # Should be (n_samples,)\n",
    "\n",
    "Catches issues before they become confusing errors."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
