{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a14f1c",
   "metadata": {},
   "source": [
    "<img src=\"../assets/Header_NovaAi_Camp2.0.png\" alt=\"NovaAi Camp Header\" width=\"100%\">\n",
    "\n",
    "# ðŸŽ¯ Machine Learning Foundations - Practice Exercises\n",
    "\n",
    "\n",
    "## **Notebook Overview**\n",
    "\n",
    "Welcome to the **Machine Learning Foundations Practice Notebook**! This is your hands-on laboratory where theory transforms into practical skills. While the main theory notebook introduces concepts, **this notebook is where you BUILD, EXPERIMENT, and LEARN BY DOING**.\n",
    "\n",
    "\n",
    "### **What This Notebook Is For:**\n",
    "\n",
    "This exercise notebook is designed to:\n",
    "\n",
    "1. **âœ‹ Hands-On Practice** - Work with real-world data (California Housing Dataset) to reinforce theoretical concepts\n",
    "2. **ðŸ”¬ Experimentation** - Test ML algorithms, compare models, and see concepts in action\n",
    "3. **ðŸ’¡ Deep Understanding** - Move beyond memorization to genuine comprehension through practice\n",
    "4. **ðŸ› ï¸ Skill Building** - Develop practical coding skills in data preparation, modeling, and evaluation\n",
    "5. **ðŸŽ¯ Self-Assessment** - Challenge yourself with exercises that mirror real ML workflows\n",
    "\n",
    "### ðŸ—ºï¸ **What You'll Practice:**\n",
    "\n",
    "| Part | Topic | Skills You'll Build |\n",
    "|------|-------|-------------------|\n",
    "| **Part 1** | Data Preparation | Feature scaling, encoding categorical data, handling different data types |\n",
    "| **Part 2** | Three Pillars of Learning | Training models, evaluating performance, understanding train/test splits |\n",
    "| **Part 3** | Generalization | Finding optimal model complexity, avoiding overfitting/underfitting |\n",
    "| **Part 4** | Classification Metrics | Calculating precision, recall, F1-score, understanding metric trade-offs |\n",
    "| **Part 5** | Cross-Validation | Implementing k-fold CV, measuring model stability, robust evaluation |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ðŸ“Š **About the Dataset**\n",
    "\n",
    "### **California Housing Dataset**\n",
    "\n",
    "You'll work with real housing data from the 1990 California census:\n",
    "\n",
    "- ðŸ˜ï¸ **20,640 districts** in California\n",
    "- ðŸ“ˆ **8 features**: Median income, house age, rooms, bedrooms, population, occupancy, location (lat/lon)\n",
    "- ðŸŽ¯ **Target**: Median house price (in $100,000s)\n",
    "- ðŸ’¼ **Real-world application**: Predicting housing prices based on demographic and geographic data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ **How to Use This Notebook**\n",
    "\n",
    "### **Step 1: Read Carefully**\n",
    "Each exercise includes:\n",
    "- ðŸ“– **Context** - What you're learning and why it matters\n",
    "- ðŸŽ¯ **Task** - Clear instructions on what to implement\n",
    "- ðŸ’¡ **Hints** - Guidance to help you succeed\n",
    "- ðŸ¤” **Critical Thinking** - Questions to deepen understanding\n",
    "\n",
    "### **Step 2: Complete TODOs**\n",
    "Look for `# TODO:` comments in code cells. These mark where YOU need to write code.\n",
    "\n",
    "### **Step 3: Run and Observe**\n",
    "Execute cells and carefully examine outputs. What do the numbers tell you? What do visualizations reveal?\n",
    "\n",
    "### **Step 4: Reflect**\n",
    "Answer the critical thinking questions. Understanding WHY is as important as knowing HOW.\n",
    "\n",
    "### **Step 5: Experiment**\n",
    "After completing exercises, try variations:\n",
    "- Change hyperparameters\n",
    "- Use different features\n",
    "- Test alternative algorithms\n",
    "- Break things and fix them!\n",
    "\n",
    "\n",
    "Let's begin with loading our tools and data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911c853",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¦ **Step 1: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea53449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ðŸ“Š NumPy version: {np.__version__}\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a88aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **Step 2: Load California Housing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ba25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Create DataFrame with features\n",
    "df = california.data\n",
    "df['Price'] = california.target  # Add target variable\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"\\nðŸ“¦ Dataset Shape: {df.shape}\")\n",
    "print(f\"   - {df.shape[0]:,} samples (districts)\")\n",
    "print(f\"   - {df.shape[1]} columns (8 features + 1 target)\")\n",
    "print(f\"\\nðŸ“Š Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b74534",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ” **Step 3: Explore the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0afb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"ðŸ“‹ First 5 rows of the dataset:\")\n",
    "print(\"=\"*80)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nðŸ“Š Dataset Info:\")\n",
    "print(\"=\"*80)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Statistical Summary:\")\n",
    "print(\"=\"*80)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f3572",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **Step 4: Visualize Target Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba35752",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Price'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['Price'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${df[\"Price\"].mean():.2f}00k')\n",
    "axes[0].axvline(df['Price'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: ${df[\"Price\"].median():.2f}00k')\n",
    "axes[0].set_xlabel('House Price ($100,000s)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribution of House Prices', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Price'], vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                medianprops=dict(color='red', linewidth=2),\n",
    "                whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                capprops=dict(color='black', linewidth=1.5))\n",
    "axes[1].set_ylabel('House Price ($100,000s)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Box Plot of House Prices', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“Š Price Statistics:\")\n",
    "print(f\"   Min:    ${df['Price'].min():.2f}00k\")\n",
    "print(f\"   Max:    ${df['Price'].max():.2f}00k\")\n",
    "print(f\"   Mean:   ${df['Price'].mean():.2f}00k\")\n",
    "print(f\"   Median: ${df['Price'].median():.2f}00k\")\n",
    "print(f\"   Std:    ${df['Price'].std():.2f}00k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c32de1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ—ºï¸ **Step 5: Feature Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f830e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show features most correlated with Price\n",
    "print(\"\\nðŸŽ¯ Features Most Correlated with Price:\")\n",
    "print(\"=\"*50)\n",
    "price_corr = correlation_matrix['Price'].sort_values(ascending=False)\n",
    "for feature, corr in price_corr.items():\n",
    "    if feature != 'Price':\n",
    "        print(f\"   {feature:15} {corr:+.3f}  {'ðŸ“ˆ' if corr > 0 else 'ðŸ“‰'}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: MedInc (Median Income) has the strongest positive correlation with Price!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c03164",
   "metadata": {},
   "source": [
    "## âœ… **Dataset Ready!**\n",
    "\n",
    "You now have:\n",
    "- âœ… **20,640 samples** of California housing data\n",
    "- âœ… **8 features** describing each district\n",
    "- âœ… **1 target** (median house price)\n",
    "- âœ… **No missing values** in this dataset\n",
    "- âœ… **Understanding** of feature distributions and correlations\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# ðŸŽ¯ **Now Let's Start the Exercises!**\n",
    "\n",
    "The following sections contain exercises organized by topic. Complete them in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd98695",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ðŸ“š **PART 1: Data Preparation Exercises**\n",
    "\n",
    "## ðŸŽ¯ **Learning Objectives**\n",
    "\n",
    "In this section, you'll practice:\n",
    "- âœ… Handling data at different scales with StandardScaler\n",
    "- âœ… Understanding when to use Label vs. One-Hot Encoding\n",
    "- âœ… Preparing real-world data for machine learning models\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ **Exercise 1.1: Feature Scaling**\n",
    "\n",
    "**Scenario:** The California Housing dataset has features at very different scales:\n",
    "- `MedInc` (Median Income): ranges from 0.5 to 15\n",
    "- `Population`: ranges from 3 to 35,000+\n",
    "\n",
    "**Task:** Scale the features and observe the impact!\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Select two features with very different scales\n",
    "2. Print statistics BEFORE scaling\n",
    "3. Apply `StandardScaler` from sklearn\n",
    "4. Print statistics AFTER scaling\n",
    "5. Visualize the before/after comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74391a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 1.1 - YOUR CODE HERE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Select two features with different scales\n",
    "# feature1 = 'MedInc'\n",
    "# feature2 = 'Population'\n",
    "\n",
    "# TODO: Print BEFORE scaling statistics\n",
    "# print(\"ðŸ“Š BEFORE Scaling:\")\n",
    "# print(\"=\"*60)\n",
    "# print(df[[feature1, feature2]].describe())\n",
    "\n",
    "# TODO: Apply StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df_scaled = df.copy()\n",
    "# df_scaled[[feature1, feature2]] = scaler.fit_transform(df[[feature1, feature2]])\n",
    "\n",
    "# TODO: Print AFTER scaling statistics\n",
    "# print(\"\\nðŸ“Š AFTER Scaling:\")\n",
    "# print(\"=\"*60)\n",
    "# print(df_scaled[[feature1, feature2]].describe())\n",
    "\n",
    "# TODO: Visualize before vs after\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# \n",
    "# # Before\n",
    "# axes[0].scatter(df[feature1], df[feature2], alpha=0.5, s=10)\n",
    "# axes[0].set_xlabel(feature1, fontweight='bold')\n",
    "# axes[0].set_ylabel(feature2, fontweight='bold')\n",
    "# axes[0].set_title('BEFORE Scaling', fontweight='bold')\n",
    "# axes[0].grid(alpha=0.3)\n",
    "# \n",
    "# # After\n",
    "# axes[1].scatter(df_scaled[feature1], df_scaled[feature2], alpha=0.5, s=10, color='green')\n",
    "# axes[1].set_xlabel(f'{feature1} (scaled)', fontweight='bold')\n",
    "# axes[1].set_ylabel(f'{feature2} (scaled)', fontweight='bold')\n",
    "# axes[1].set_title('AFTER Scaling', fontweight='bold')\n",
    "# axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "# axes[1].axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "# axes[1].grid(alpha=0.3)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# =================\n",
    "# Q1: What is the mean and std of scaled features?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: Why is scaling important for ML models?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce981a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”¢ **Exercise 1.2: Label vs One-Hot Encoding**\n",
    "\n",
    "**Challenge:** Understanding when to use each encoding method!\n",
    "\n",
    "**Scenario:** You're building a model to predict house prices. Your dataset has a new categorical feature `OceanProximity` with values:\n",
    "- `'NEAR BAY'`\n",
    "- `'<1H OCEAN'`  \n",
    "- `'INLAND'`\n",
    "- `'NEAR OCEAN'`\n",
    "- `'ISLAND'`\n",
    "\n",
    "### Task 1: Label Encoding (The Wrong Way!)\n",
    "\n",
    "Apply Label Encoding and see what problems it creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca06760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 1.2 PART A - Label Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data: Ocean proximity categories\n",
    "ocean_proximity = ['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND',\n",
    "                   'NEAR BAY', 'INLAND', '<1H OCEAN', 'INLAND', 'NEAR BAY']\n",
    "\n",
    "print(\"ðŸ“‹ Original Categories:\")\n",
    "print(ocean_proximity)\n",
    "\n",
    "# TODO: Apply Label Encoding\n",
    "# label_enc = LabelEncoder()\n",
    "# encoded = label_enc.fit_transform(ocean_proximity)\n",
    "\n",
    "# TODO: Print the mapping\n",
    "# print(\"\\nðŸ”¢ Label Encoding Result:\")\n",
    "# print(encoded)\n",
    "# print(\"\\nðŸ“Š Category Mapping:\")\n",
    "# for category, label in zip(label_enc.classes_, range(len(label_enc.classes_))):\n",
    "#     print(f\"   '{category}' â†’ {label}\")\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: What's the problem with this encoding?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "#\n",
    "# Q2: Does it make sense that ISLAND=2 > INLAND=1 > <1H OCEAN=0?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q3: Will the model think \"ISLAND\" is \"twice as much\" as \"<1H OCEAN\"?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3324a",
   "metadata": {},
   "source": [
    "### Task 2: One-Hot Encoding (The Right Way!)\n",
    "\n",
    "Now use One-Hot Encoding to properly handle nominal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 1.2 PART B - One-Hot Encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Apply One-Hot Encoding\n",
    "# onehot_enc = OneHotEncoder(sparse_output=False, drop='first')\n",
    "# encoded_onehot = onehot_enc.fit_transform(np.array(ocean_proximity).reshape(-1, 1))\n",
    "\n",
    "# TODO: Create DataFrame to see the result clearly\n",
    "# feature_names = onehot_enc.get_feature_names_out(['OceanProximity'])\n",
    "# df_encoded = pd.DataFrame(encoded_onehot, columns=feature_names)\n",
    "\n",
    "# print(\"ðŸ”¢ One-Hot Encoding Result:\")\n",
    "# print(df_encoded)\n",
    "\n",
    "# print(\"\\nðŸ“Š What each column means:\")\n",
    "# for col in feature_names:\n",
    "#     print(f\"   {col}: 1 if {col.split('_')[1]}, 0 otherwise\")\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: How many columns were created?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: Why did we drop the first category?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q3: How does this solve the ordering problem from Label Encoding?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q4: When would you use Label Encoding instead?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e30c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ›ï¸ **PART 2: Three Pillars of Learning - Regression Exercise**\n",
    "\n",
    "## ðŸŽ¯ **Learning Objectives**\n",
    "\n",
    "Practice building a regression model and understanding the three pillars:\n",
    "- âœ… Build a linear regression model\n",
    "- âœ… Calculate loss metrics (MSE, MAE, RÂ²)\n",
    "- âœ… Understand the importance of train/test split\n",
    "- âœ… Analyze model performance\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š **Exercise 2: Predicting House Prices**\n",
    "\n",
    "**Task:** Build a regression model to predict California house prices based on median income!\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Split the data into train/test sets (80/20)\n",
    "2. Train a Linear Regression model using `MedInc` feature\n",
    "3. Calculate MSE, MAE, and RÂ² for both train and test sets\n",
    "4. Visualize predictions vs actual values\n",
    "5. Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 2 - YOUR CODE HERE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Prepare data: X = MedInc (median income), y = Price\n",
    "X_income = df[['MedInc']].values\n",
    "y_price = df['Price'].values\n",
    "\n",
    "# TODO: Split into train/test (80/20)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_income, y_price, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# TODO: Create and train the model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Make predictions\n",
    "# y_train_pred = model.predict(X_train)\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# TODO: Calculate metrics for TRAINING set\n",
    "# train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "# train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "# train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# TODO: Calculate metrics for TEST set\n",
    "# test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "# test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "# test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# TODO: Print results\n",
    "# print(\"ðŸ“Š MODEL PERFORMANCE\")\n",
    "# print(\"=\"*60)\n",
    "# print(f\"\\nðŸ‹ï¸ TRAINING SET:\")\n",
    "# print(f\"   MSE:  {train_mse:.4f}\")\n",
    "# print(f\"   MAE:  {train_mae:.4f}\")\n",
    "# print(f\"   RÂ²:   {train_r2:.4f}\")\n",
    "#\n",
    "# print(f\"\\nðŸ§ª TEST SET:\")\n",
    "# print(f\"   MSE:  {test_mse:.4f}\")\n",
    "# print(f\"   MAE:  {test_mae:.4f}\")\n",
    "# print(f\"   RÂ²:   {test_r2:.4f}\")\n",
    "#\n",
    "# print(f\"\\nðŸ“ˆ Model Parameters:\")\n",
    "# print(f\"   Weight (slope):     {model.coef_[0]:.4f}\")\n",
    "# print(f\"   Intercept (bias):   {model.intercept_:.4f}\")\n",
    "\n",
    "# TODO: Visualize predictions\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# \n",
    "# # Scatter plot\n",
    "# plt.scatter(X_test, y_test, alpha=0.5, s=20, label='Actual Prices', color='blue')\n",
    "# plt.scatter(X_test, y_test_pred, alpha=0.5, s=20, label='Predicted Prices', color='red')\n",
    "# \n",
    "# # Regression line\n",
    "# X_range = np.linspace(X_income.min(), X_income.max(), 100).reshape(-1, 1)\n",
    "# y_range = model.predict(X_range)\n",
    "# plt.plot(X_range, y_range, color='green', linewidth=3, label='Regression Line')\n",
    "# \n",
    "# plt.xlabel('Median Income', fontweight='bold')\n",
    "# plt.ylabel('House Price ($100k)', fontweight='bold')\n",
    "# plt.title('House Price vs. Median Income', fontweight='bold')\n",
    "# plt.legend()\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: Is the test RÂ² close to the train RÂ²? What does this mean?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: What does the weight (slope) tell you about the relationship?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q3: If train error is much lower than test error, what's the problem?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124db01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ¯ **PART 3: Generalization - Finding the Right Complexity**\n",
    "\n",
    "## ðŸŽ¯ **Learning Objectives**\n",
    "\n",
    "Understand the generalization problem:\n",
    "- âœ… Recognize underfitting (high bias)\n",
    "- âœ… Recognize overfitting (high variance)\n",
    "- âœ… Find the optimal model complexity\n",
    "- âœ… Understand bias-variance tradeoff\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ **Exercise 3: Polynomial Regression Experiment**\n",
    "\n",
    "**Challenge:** Find the optimal polynomial degree for predicting house prices!\n",
    "\n",
    "**Background:** Linear models might be too simple. Polynomial features can capture non-linear relationships:\n",
    "- Degree 1: $y = w_1x + b$ (linear - might underfit)\n",
    "- Degree 2: $y = w_1x + w_2x^2 + b$ (quadratic)\n",
    "- Degree 3: $y = w_1x + w_2x^2 + w_3x^3 + b$ (cubic)\n",
    "\n",
    "**But:** Higher degree doesn't always mean better! Too high = overfitting!\n",
    "\n",
    "### Task: Compare Multiple Polynomial Degrees\n",
    "\n",
    "Test degrees 1, 2, 3, 5, and 10. Find which generalizes best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 3 - YOUR CODE HERE\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Use MedInc to predict Price\n",
    "X_med = df[['MedInc']].values\n",
    "y_price = df['Price'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_med, y_price, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Degrees to test\n",
    "degrees = [1, 2, 3, 5, 10]\n",
    "results = []\n",
    "\n",
    "# TODO: Loop through each degree\n",
    "# for degree in degrees:\n",
    "#     # Create polynomial model\n",
    "#     model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "#     \n",
    "#     # Train\n",
    "#     model.fit(X_train, y_train)\n",
    "#     \n",
    "#     # Predict\n",
    "#     y_train_pred = model.predict(X_train)\n",
    "#     y_test_pred = model.predict(X_test)\n",
    "#     \n",
    "#     # Calculate MSE\n",
    "#     train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "#     test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "#     gap = test_mse - train_mse\n",
    "#     \n",
    "#     results.append({\n",
    "#         'degree': degree,\n",
    "#         'train_mse': train_mse,\n",
    "#         'test_mse': test_mse,\n",
    "#         'gap': gap\n",
    "#     })\n",
    "\n",
    "# TODO: Print comparison table\n",
    "# print(\"ðŸ”¬ POLYNOMIAL DEGREE COMPARISON\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"{'Degree':<10} {'Train MSE':<15} {'Test MSE':<15} {'Gap':<15} {'Status':<15}\")\n",
    "# print(\"=\"*70)\n",
    "# for r in results:\n",
    "#     status = 'âœ… Good' if r['gap'] < 0.1 else 'âš ï¸ Overfitting' if r['gap'] > 0.3 else 'ðŸ”¶ Borderline'\n",
    "#     print(f\"{r['degree']:<10} {r['train_mse']:<15.4f} {r['test_mse']:<15.4f} {r['gap']:<15.4f} {status:<15}\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# TODO: Visualize the comparison\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "# \n",
    "# # Left: Train vs Test MSE\n",
    "# degrees_list = [r['degree'] for r in results]\n",
    "# train_mses = [r['train_mse'] for r in results]\n",
    "# test_mses = [r['test_mse'] for r in results]\n",
    "# \n",
    "# axes[0].plot(degrees_list, train_mses, 'o-', label='Train MSE', linewidth=2, markersize=8)\n",
    "# axes[0].plot(degrees_list, test_mses, 's-', label='Test MSE', linewidth=2, markersize=8)\n",
    "# axes[0].set_xlabel('Polynomial Degree', fontweight='bold')\n",
    "# axes[0].set_ylabel('MSE', fontweight='bold')\n",
    "# axes[0].set_title('Training vs Test Error', fontweight='bold')\n",
    "# axes[0].legend()\n",
    "# axes[0].grid(alpha=0.3)\n",
    "# \n",
    "# # Right: Generalization Gap\n",
    "# gaps = [r['gap'] for r in results]\n",
    "# colors = ['green' if g < 0.1 else 'orange' if g < 0.3 else 'red' for g in gaps]\n",
    "# axes[1].bar(degrees_list, gaps, color=colors, edgecolor='black', linewidth=2)\n",
    "# axes[1].set_xlabel('Polynomial Degree', fontweight='bold')\n",
    "# axes[1].set_ylabel('Generalization Gap (Test - Train)', fontweight='bold')\n",
    "# axes[1].set_title('Overfitting Analysis', fontweight='bold')\n",
    "# axes[1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# axes[1].grid(alpha=0.3, axis='y')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: Which degree has the lowest test MSE?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: Which degree shows signs of overfitting (large gap)?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q3: Explain the bias-variance tradeoff you observe\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q4: Why doesn't degree 10 perform best despite being most complex?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4087a56",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š **PART 4: Classification Metrics - Beyond Accuracy**\n",
    "\n",
    "## ðŸŽ¯ **Learning Objectives**\n",
    "\n",
    "Master classification evaluation:\n",
    "- âœ… Understand the Accuracy Paradox\n",
    "- âœ… Build and interpret confusion matrices\n",
    "- âœ… Calculate Precision, Recall, and F1-Score manually\n",
    "- âœ… Choose metrics based on problem cost\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¥ **Exercise 4: Medical Diagnosis - Cost-Sensitive Metrics**\n",
    "\n",
    "**Scenario:** You're building a disease detection model. The confusion matrix shows:\n",
    "\n",
    "```\n",
    "                Actually Healthy    Actually Sick\n",
    "Pred Healthy         950                 8\n",
    "Pred Sick             30                12\n",
    "```\n",
    "\n",
    "**Context:**\n",
    "- Total patients: 1,000\n",
    "- Actually sick: 20 (2% - imbalanced!)\n",
    "- Actually healthy: 980 (98%)\n",
    "\n",
    "### Tasks:\n",
    "\n",
    "1. **Calculate metrics MANUALLY** (no sklearn - show your math!)\n",
    "2. **Analyze the results**\n",
    "3. **Make recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 4 - YOUR CODE HERE\n",
    "\n",
    "# Given confusion matrix:\n",
    "TN = 950  # True Negatives (correctly predicted healthy)\n",
    "FP = 30   # False Positives (healthy predicted sick - false alarm)\n",
    "FN = 8    # False Negatives (sick predicted healthy - DANGEROUS!)\n",
    "TP = 12   # True Positives (correctly predicted sick)\n",
    "\n",
    "print(\"ðŸ¥ MEDICAL DIAGNOSIS METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“Š Confusion Matrix:\")\n",
    "print(f\"                Actually Healthy    Actually Sick\")\n",
    "print(f\"Pred Healthy         {TN:<15}     {FN:<10}\")\n",
    "print(f\"Pred Sick            {FP:<15}     {TP:<10}\")\n",
    "\n",
    "# TODO: Calculate Accuracy\n",
    "# Total = TN + FP + FN + TP\n",
    "# Accuracy = (TP + TN) / Total\n",
    "# print(f\"\\n1ï¸âƒ£ ACCURACY:\")\n",
    "# print(f\"   Formula: (TP + TN) / Total\")\n",
    "# print(f\"   Calculation: ({TP} + {TN}) / {Total}\")\n",
    "# print(f\"   Result: {Accuracy:.4f} ({Accuracy*100:.2f}%)\")\n",
    "\n",
    "# TODO: Calculate Precision (for sick class)\n",
    "# Precision = TP / (TP + FP)\n",
    "# print(f\"\\n2ï¸âƒ£ PRECISION (for sick class):\")\n",
    "# print(f\"   Formula: TP / (TP + FP)\")\n",
    "# print(f\"   Calculation: {TP} / ({TP} + {FP})\")\n",
    "# print(f\"   Result: {Precision:.4f} ({Precision*100:.2f}%)\")\n",
    "# print(f\"   Meaning: Of all predicted sick, {Precision*100:.1f}% actually were sick\")\n",
    "\n",
    "# TODO: Calculate Recall/Sensitivity (for sick class)\n",
    "# Recall = TP / (TP + FN)\n",
    "# print(f\"\\n3ï¸âƒ£ RECALL/SENSITIVITY (for sick class):\")\n",
    "# print(f\"   Formula: TP / (TP + FN)\")\n",
    "# print(f\"   Calculation: {TP} / ({TP} + {FN})\")\n",
    "# print(f\"   Result: {Recall:.4f} ({Recall*100:.2f}%)\")\n",
    "# print(f\"   Meaning: Of all actually sick patients, we caught {Recall*100:.1f}%\")\n",
    "\n",
    "# TODO: Calculate F1-Score\n",
    "# F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "# print(f\"\\n4ï¸âƒ£ F1-SCORE:\")\n",
    "# print(f\"   Formula: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)\")\n",
    "# print(f\"   Calculation: 2 Ã— ({Precision:.4f} Ã— {Recall:.4f}) / ({Precision:.4f} + {Recall:.4f})\")\n",
    "# print(f\"   Result: {F1:.4f} ({F1*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: The accuracy is 96.2%! Is this a good model? Why or why not?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: Which is worse in this scenario: False Positive or False Negative? Explain.\n",
    "# YOUR ANSWER (Think about real-world consequences!):\n",
    "#\n",
    "#\n",
    "# Q3: Which metric is MOST important for medical diagnosis? Why?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q4: How would you improve this model?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q5: What if we predicted EVERYONE as healthy?\n",
    "# Calculate: Accuracy = ?   Recall = ?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d99670",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”„ **PART 5: Cross-Validation - Robust Model Evaluation**\n",
    "\n",
    "## ðŸŽ¯ **Learning Objectives**\n",
    "\n",
    "Master robust evaluation:\n",
    "- âœ… Understand why single split is unreliable\n",
    "- âœ… Implement K-Fold Cross-Validation\n",
    "- âœ… Compare different k values\n",
    "- âœ… Analyze model stability\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª **Exercise 5: K-Fold Experiments**\n",
    "\n",
    "**Challenge:** Test how different k values affect cross-validation results!\n",
    "\n",
    "**Background:**\n",
    "- k=3: Fast but less reliable (only 3 tests)\n",
    "- k=5: Standard choice (good balance)\n",
    "- k=10: More reliable but slower\n",
    "- k=20: Very stable but expensive\n",
    "\n",
    "### Task: Compare k=3, k=5, k=10, and k=20\n",
    "\n",
    "Use the California Housing data and compare cross-validation with different k values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 5 - YOUR CODE HERE\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# Prepare data\n",
    "X_cv = df[['MedInc']].values\n",
    "y_cv = df['Price'].values\n",
    "\n",
    "# Create model\n",
    "model_cv = LinearRegression()\n",
    "\n",
    "# K values to test\n",
    "k_values = [3, 5, 10, 20]\n",
    "results = []\n",
    "\n",
    "# TODO: Loop through each k value\n",
    "# for k in k_values:\n",
    "#     # Create KFold splitter\n",
    "#     kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "#     \n",
    "#     # Time the cross-validation\n",
    "#     start_time = time.time()\n",
    "#     scores = cross_val_score(model_cv, X_cv, y_cv, cv=kfold, \n",
    "#                              scoring='neg_mean_squared_error')\n",
    "#     end_time = time.time()\n",
    "#     \n",
    "#     # Convert to positive MSE\n",
    "#     mse_scores = -scores\n",
    "#     \n",
    "#     results.append({\n",
    "#         'k': k,\n",
    "#         'mean_mse': mse_scores.mean(),\n",
    "#         'std_mse': mse_scores.std(),\n",
    "#         'min_mse': mse_scores.min(),\n",
    "#         'max_mse': mse_scores.max(),\n",
    "#         'time': end_time - start_time\n",
    "#     })\n",
    "\n",
    "# TODO: Print comparison table\n",
    "# print(\"ðŸ”„ K-FOLD CROSS-VALIDATION COMPARISON\")\n",
    "# print(\"=\"*90)\n",
    "# print(f\"{'k':<5} {'Mean MSE':<12} {'Std MSE':<12} {'Min MSE':<12} {'Max MSE':<12} {'Time (s)':<10}\")\n",
    "# print(\"=\"*90)\n",
    "# for r in results:\n",
    "#     print(f\"{r['k']:<5} {r['mean_mse']:<12.4f} {r['std_mse']:<12.4f} \"\n",
    "#           f\"{r['min_mse']:<12.4f} {r['max_mse']:<12.4f} {r['time']:<10.3f}\")\n",
    "# print(\"=\"*90)\n",
    "\n",
    "# TODO: Visualize the results\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "# \n",
    "# k_list = [r['k'] for r in results]\n",
    "# means = [r['mean_mse'] for r in results]\n",
    "# stds = [r['std_mse'] for r in results]\n",
    "# times = [r['time'] for r in results]\n",
    "# \n",
    "# # Left: Mean MSE with error bars\n",
    "# axes[0].errorbar(k_list, means, yerr=stds, marker='o', linewidth=2, \n",
    "#                  markersize=8, capsize=5, capthick=2)\n",
    "# axes[0].set_xlabel('k (number of folds)', fontweight='bold')\n",
    "# axes[0].set_ylabel('MSE', fontweight='bold')\n",
    "# axes[0].set_title('Mean MSE Â± Std', fontweight='bold')\n",
    "# axes[0].grid(alpha=0.3)\n",
    "# \n",
    "# # Middle: Standard deviation (stability)\n",
    "# axes[1].bar(k_list, stds, color='orange', edgecolor='black', linewidth=2)\n",
    "# axes[1].set_xlabel('k (number of folds)', fontweight='bold')\n",
    "# axes[1].set_ylabel('Standard Deviation', fontweight='bold')\n",
    "# axes[1].set_title('Model Stability (Lower = More Stable)', fontweight='bold')\n",
    "# axes[1].grid(alpha=0.3, axis='y')\n",
    "# \n",
    "# # Right: Computation time\n",
    "# axes[2].plot(k_list, times, 'o-', color='red', linewidth=2, markersize=8)\n",
    "# axes[2].set_xlabel('k (number of folds)', fontweight='bold')\n",
    "# axes[2].set_ylabel('Time (seconds)', fontweight='bold')\n",
    "# axes[2].set_title('Computational Cost', fontweight='bold')\n",
    "# axes[2].grid(alpha=0.3)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# CRITICAL THINKING:\n",
    "# ==================\n",
    "# Q1: Which k value gives the lowest mean MSE?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q2: Which k value has the lowest standard deviation (most stable)?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q3: How much slower is k=20 compared to k=3?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q4: For this dataset (20,640 samples), which k would you recommend? Why?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#\n",
    "# Q5: What happens if k equals the number of samples (k=20640)?\n",
    "# YOUR ANSWER (this is called LOOCV - Leave-One-Out Cross-Validation):\n",
    "#\n",
    "#\n",
    "# Q6: When would you use k=3 despite it being less stable?\n",
    "# YOUR ANSWER:\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
